{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-23T12:00:00.770149Z",
     "iopub.status.busy": "2024-03-23T12:00:00.769520Z",
     "iopub.status.idle": "2024-03-23T12:00:18.116329Z",
     "shell.execute_reply": "2024-03-23T12:00:18.115338Z",
     "shell.execute_reply.started": "2024-03-23T12:00:00.770118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/working', '/kaggle/lib/kagglegym', '/kaggle/lib', '/opt/conda/lib/python310.zip', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/root/.local/lib/python3.10/site-packages', '/opt/conda/lib/python3.10/site-packages', '/root/src/BigQuery_Helper', '../input']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 12:00:02.501380: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-23 12:00:02.501481: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-23 12:00:02.628798: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../input')\n",
    "print(sys.path)\n",
    "\n",
    "import os\n",
    "import keras\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T12:00:18.118556Z",
     "iopub.status.busy": "2024-03-23T12:00:18.118022Z",
     "iopub.status.idle": "2024-03-23T12:00:18.149149Z",
     "shell.execute_reply": "2024-03-23T12:00:18.148220Z",
     "shell.execute_reply.started": "2024-03-23T12:00:18.118528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T12:00:18.151169Z",
     "iopub.status.busy": "2024-03-23T12:00:18.150529Z",
     "iopub.status.idle": "2024-03-23T12:00:18.161181Z",
     "shell.execute_reply": "2024-03-23T12:00:18.160109Z",
     "shell.execute_reply.started": "2024-03-23T12:00:18.151135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# 使用GPU加速运算\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T12:00:18.163453Z",
     "iopub.status.busy": "2024-03-23T12:00:18.163169Z",
     "iopub.status.idle": "2024-03-23T12:00:18.170848Z",
     "shell.execute_reply": "2024-03-23T12:00:18.170106Z",
     "shell.execute_reply.started": "2024-03-23T12:00:18.163423Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据并预处理\n",
    "species_data = []\n",
    "species_labels = []\n",
    "\n",
    "data_folder = \"/kaggle/input/dna-sequence/DNA_sequence\"\n",
    "files = [\"chimpanzee.txt\", \"dog.txt\", \"human.txt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T12:00:18.171997Z",
     "iopub.status.busy": "2024-03-23T12:00:18.171744Z",
     "iopub.status.idle": "2024-03-23T12:00:18.362829Z",
     "shell.execute_reply": "2024-03-23T12:00:18.361953Z",
     "shell.execute_reply.started": "2024-03-23T12:00:18.171956Z"
    }
   },
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    file_path = os.path.join(data_folder, file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        # 跳过标题行,也就是首行\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            sequence = line.split()[0]\n",
    "            species_data.append(sequence)\n",
    "            species_labels.append(file.split(\".\")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T12:00:18.364629Z",
     "iopub.status.busy": "2024-03-23T12:00:18.364232Z",
     "iopub.status.idle": "2024-03-23T12:00:18.406631Z",
     "shell.execute_reply": "2024-03-23T12:00:18.405803Z",
     "shell.execute_reply.started": "2024-03-23T12:00:18.364592Z"
    }
   },
   "outputs": [],
   "source": [
    "# 划分数据，原始数据为5000\n",
    "train_sz = (5000.0/len(species_data))\n",
    "sequences, _sequences, class_label, _class_label = train_test_split(\n",
    "    species_data, species_labels, train_size=train_sz, random_state=42, stratify=species_labels)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(sequences, class_label, test_size=0.2, random_state=42,\n",
    "                                                            stratify=class_label)# 将标签编码为数字\n",
    "label_mapping = {\"chimpanzee\": 0, \"dog\": 1, \"human\": 2}\n",
    "species_labels_encoded = [label_mapping[label] for label in species_labels]\n",
    "\n",
    "# 划分数据\n",
    "train_sz = (500.0/len(species_data))\n",
    "sequences, _sequences, class_label, _class_label = train_test_split(\n",
    "    species_data, species_labels_encoded, train_size=train_sz, random_state=42, stratify=species_labels_encoded)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(sequences, class_label, test_size=0.2, random_state=42,\n",
    "                                                            stratify=class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T12:00:18.408089Z",
     "iopub.status.busy": "2024-03-23T12:00:18.407759Z",
     "iopub.status.idle": "2024-03-23T12:00:25.419396Z",
     "shell.execute_reply": "2024-03-23T12:00:25.418430Z",
     "shell.execute_reply.started": "2024-03-23T12:00:18.408064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 2, 31752)\n"
     ]
    }
   ],
   "source": [
    "class SeqEmbedding():\n",
    "    def __init__(self):\n",
    "        self.Dictionary = {}\n",
    "\n",
    "    def __Sequence_to_Numeric(self, k, sequence):\n",
    "        if k == 0:\n",
    "            temp = [0] * self.size_of_vector\n",
    "            temp[len(self.Dictionary)] = 1\n",
    "            self.Dictionary[sequence] = temp\n",
    "            return\n",
    "        nucleotide = ['A', 'C', 'G', 'T']\n",
    "        for n in nucleotide:\n",
    "            self.__Sequence_to_Numeric(k - 1, sequence + n)\n",
    "        return\n",
    "\n",
    "    def fit(self, sequences, window_size, stride_size):\n",
    "        self.size_of_vector = 4 ** window_size\n",
    "        self.__Sequence_to_Numeric(window_size, \"\")\n",
    "\n",
    "        vectorized = []\n",
    "\n",
    "        for seq in sequences:\n",
    "            first_layer_embedding = []\n",
    "            for k in range(window_size, len(seq) + 1, stride_size):\n",
    "                try:\n",
    "                    first_layer_embedding.append(self.Dictionary[seq[k - window_size:k]])\n",
    "                except:\n",
    "                    # exception may occur because of stride size, sometimes it may not get sequence of length window\n",
    "                    # size, there will be a key not found exception in Dictionary\n",
    "                    first_layer_embedding.append([0] * self.size_of_vector)\n",
    "\n",
    "            vector0 = []\n",
    "            vector1 = []\n",
    "            for i in range(len(first_layer_embedding)):\n",
    "                if i > 0:\n",
    "                    vector1 += first_layer_embedding[i]\n",
    "                vector0 += first_layer_embedding[i]\n",
    "            vector1 += first_layer_embedding[0]\n",
    "\n",
    "            vectorized.append([vector0, vector1])\n",
    "\n",
    "        # Handling inequal length problem using zero padding\n",
    "        max_len = 0\n",
    "        for vec in vectorized:\n",
    "            max_len = max(max_len, len(vec[0]))\n",
    "        for i in range(len(vectorized)):\n",
    "            required = max_len - len(vectorized[i][0])\n",
    "\n",
    "            vectorized[i][0] += ([0] * required)\n",
    "            vectorized[i][0] = vectorized[i][0][:31752]  # to fit into 252 * 252 pixel size, removing 120 elements\n",
    "            vectorized[i][0] = np.array(vectorized[i][0])\n",
    "\n",
    "            vectorized[i][1] += ([0] * required)\n",
    "            vectorized[i][1] = vectorized[i][1][:31752]  # to fit into 252 * 252 pixel size, removing 120 elements\n",
    "            vectorized[i][1] = np.array(vectorized[i][1])\n",
    "\n",
    "            vectorized[i] = np.array(vectorized[i])\n",
    "\n",
    "        return np.array(vectorized)\n",
    "\n",
    "\n",
    "instance = SeqEmbedding()\n",
    "X_train_val = instance.fit(sequences=X_train_val, window_size=3, stride_size=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1, random_state=42,\n",
    "                                                  stratify=y_train_val)\n",
    "# 观察输入数据形状格式是否正确\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T12:00:25.421283Z",
     "iopub.status.busy": "2024-03-23T12:00:25.420950Z",
     "iopub.status.idle": "2024-03-23T12:00:25.729985Z",
     "shell.execute_reply": "2024-03-23T12:00:25.729015Z",
     "shell.execute_reply.started": "2024-03-23T12:00:25.421257Z"
    }
   },
   "outputs": [],
   "source": [
    "# 转化类型适应CPU和GPU处理\n",
    "X_train = torch.tensor(X_train).to(device)\n",
    "X_val = torch.tensor(X_val).to(device)\n",
    "\n",
    "y_train = torch.tensor(y_train).to(device)\n",
    "y_val = torch.tensor(y_val).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T12:00:25.731572Z",
     "iopub.status.busy": "2024-03-23T12:00:25.731207Z",
     "iopub.status.idle": "2024-03-23T12:00:25.738594Z",
     "shell.execute_reply": "2024-03-23T12:00:25.737729Z",
     "shell.execute_reply.started": "2024-03-23T12:00:25.731546Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],252, 252, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 252, 252, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T12:00:25.742699Z",
     "iopub.status.busy": "2024-03-23T12:00:25.741950Z",
     "iopub.status.idle": "2024-03-23T12:00:27.187841Z",
     "shell.execute_reply": "2024-03-23T12:00:27.187036Z",
     "shell.execute_reply.started": "2024-03-23T12:00:25.742673Z"
    }
   },
   "outputs": [],
   "source": [
    "ins = SeqEmbedding()\n",
    "X_test = ins.fit(sequences=X_test,window_size = 3, stride_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T12:00:27.189387Z",
     "iopub.status.busy": "2024-03-23T12:00:27.189001Z",
     "iopub.status.idle": "2024-03-23T12:02:04.735269Z",
     "shell.execute_reply": "2024-03-23T12:02:04.734483Z",
     "shell.execute_reply.started": "2024-03-23T12:00:27.189355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">123</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">123</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59536</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,953,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m123\u001b[0m, \u001b[38;5;34m123\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m2,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59536\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │     \u001b[38;5;34m5,953,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m202\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,956,382</span> (22.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,956,382\u001b[0m (22.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,956,382</span> (22.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,956,382\u001b[0m (22.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 12:00:32.144682: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[360,16,250,250]{3,2,1,0}, u8[0]{0}) custom-call(f32[360,1,252,252]{3,2,1,0}, f32[16,1,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2024-03-23 12:00:33.661696: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 2.21048, expected 1.66744\n",
      "2024-03-23 12:00:33.661753: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 2.48688, expected 1.94383\n",
      "2024-03-23 12:00:33.661763: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 2.12015, expected 1.57711\n",
      "2024-03-23 12:00:33.661771: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 2.70169, expected 2.15864\n",
      "2024-03-23 12:00:33.661784: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 2.7008, expected 2.15775\n",
      "2024-03-23 12:00:33.661792: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 2.10013, expected 1.55709\n",
      "2024-03-23 12:00:33.661800: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 2.83843, expected 2.29539\n",
      "2024-03-23 12:00:33.661808: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 2.22925, expected 1.68621\n",
      "2024-03-23 12:00:33.661815: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 2.25137, expected 1.70832\n",
      "2024-03-23 12:00:33.661823: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 2.65281, expected 2.10977\n",
      "2024-03-23 12:00:33.819565: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f32[360,16,250,250]{3,2,1,0}, u8[0]{0}) custom-call(f32[360,1,252,252]{3,2,1,0}, f32[16,1,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n",
      "2024-03-23 12:00:33.819619: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n",
      "2024-03-23 12:00:33.819628: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n",
      "2024-03-23 12:00:33.819635: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n",
      "2024-03-23 12:00:33.819642: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n",
      "2024-03-23 12:00:33.819659: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n",
      "2024-03-23 12:00:33.819697: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.67525299s\n",
      "Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[360,16,250,250]{3,2,1,0}, u8[0]{0}) custom-call(f32[360,1,252,252]{3,2,1,0}, f32[16,1,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2024-03-23 12:00:36.456779: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[360,16,250,250]{3,2,1,0}, u8[0]{0}) custom-call(f32[360,1,252,252]{3,2,1,0}, f32[16,1,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2024-03-23 12:00:37.955074: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 2.21048, expected 1.66744\n",
      "2024-03-23 12:00:37.955132: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 2.48688, expected 1.94383\n",
      "2024-03-23 12:00:37.955141: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 2.12015, expected 1.57711\n",
      "2024-03-23 12:00:37.955149: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 2.70169, expected 2.15864\n",
      "2024-03-23 12:00:37.955157: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 2.7008, expected 2.15775\n",
      "2024-03-23 12:00:37.955165: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 2.10013, expected 1.55709\n",
      "2024-03-23 12:00:37.955172: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 2.83843, expected 2.29539\n",
      "2024-03-23 12:00:37.955180: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 2.22925, expected 1.68621\n",
      "2024-03-23 12:00:37.955188: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 2.25137, expected 1.70832\n",
      "2024-03-23 12:00:37.955196: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 2.65281, expected 2.10977\n",
      "2024-03-23 12:00:38.129378: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f32[360,16,250,250]{3,2,1,0}, u8[0]{0}) custom-call(f32[360,1,252,252]{3,2,1,0}, f32[16,1,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n",
      "2024-03-23 12:00:38.129436: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n",
      "2024-03-23 12:00:38.129445: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n",
      "2024-03-23 12:00:38.129452: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n",
      "2024-03-23 12:00:38.129459: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n",
      "2024-03-23 12:00:38.129476: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n",
      "2024-03-23 12:00:38.129513: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.672891087s\n",
      "Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[360,16,250,250]{3,2,1,0}, u8[0]{0}) custom-call(f32[360,1,252,252]{3,2,1,0}, f32[16,1,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2024-03-23 12:00:46.686389: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[360,1,252,252]{3,2,1,0}, f32[360,16,250,250]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2024-03-23 12:00:46.729025: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.042748418s\n",
      "Trying algorithm eng0{} for conv (f32[16,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[360,1,252,252]{3,2,1,0}, f32[360,16,250,250]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2024-03-23 12:00:49.891670: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[360,1,252,252]{3,2,1,0}, f32[360,16,250,250]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2024-03-23 12:00:49.922937: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.031378466s\n",
      "Trying algorithm eng0{} for conv (f32[16,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[360,1,252,252]{3,2,1,0}, f32[360,16,250,250]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28s/step - accuracy: 0.2000 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1711195255.846912      85 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1711195255.865620      85 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n",
      "2024-03-23 12:00:56.594891: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 62540: 1.67168, expected 1.39857\n",
      "2024-03-23 12:00:56.594949: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 62576: 1.51956, expected 1.24646\n",
      "2024-03-23 12:00:56.594959: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 62789: 1.62441, expected 1.3513\n",
      "2024-03-23 12:00:56.594976: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 62844: 1.63149, expected 1.35838\n",
      "2024-03-23 12:00:56.594993: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 63217: 1.57658, expected 1.30348\n",
      "2024-03-23 12:00:56.595005: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 63278: 1.62455, expected 1.35144\n",
      "2024-03-23 12:00:56.595019: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 63351: 1.57741, expected 1.3043\n",
      "2024-03-23 12:00:56.595032: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 63440: 1.69478, expected 1.42167\n",
      "2024-03-23 12:00:56.595040: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 63529: 1.51372, expected 1.24061\n",
      "2024-03-23 12:00:56.595049: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 63667: 1.46662, expected 1.19352\n",
      "2024-03-23 12:00:56.612501: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f32[40,16,250,250]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,1,252,252]{3,2,1,0}, f32[16,1,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n",
      "2024-03-23 12:00:56.612535: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n",
      "2024-03-23 12:00:56.612544: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n",
      "2024-03-23 12:00:56.612551: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n",
      "2024-03-23 12:00:56.612559: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n",
      "2024-03-23 12:00:56.612574: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n",
      "2024-03-23 12:00:57.080795: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 62540: 1.67168, expected 1.39857\n",
      "2024-03-23 12:00:57.080854: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 62576: 1.51956, expected 1.24646\n",
      "2024-03-23 12:00:57.080865: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 62789: 1.62441, expected 1.3513\n",
      "2024-03-23 12:00:57.080874: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 62844: 1.63149, expected 1.35838\n",
      "2024-03-23 12:00:57.080884: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 63217: 1.57658, expected 1.30348\n",
      "2024-03-23 12:00:57.080892: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 63278: 1.62455, expected 1.35144\n",
      "2024-03-23 12:00:57.080901: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 63351: 1.57741, expected 1.3043\n",
      "2024-03-23 12:00:57.080909: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 63440: 1.69478, expected 1.42167\n",
      "2024-03-23 12:00:57.080918: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 63529: 1.51372, expected 1.24061\n",
      "2024-03-23 12:00:57.080927: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 63667: 1.46662, expected 1.19352\n",
      "2024-03-23 12:00:57.098829: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f32[40,16,250,250]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,1,252,252]{3,2,1,0}, f32[16,1,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n",
      "2024-03-23 12:00:57.098871: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n",
      "2024-03-23 12:00:57.098880: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n",
      "2024-03-23 12:00:57.098887: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n",
      "2024-03-23 12:00:57.098893: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n",
      "2024-03-23 12:00:57.098908: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.12500, saving model to best_model.h5.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30s/step - accuracy: 0.2000 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 2/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 2: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 3/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 3: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 4/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 4: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 5/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 5: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 6/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 6: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 7/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 7: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 8/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 8: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 9/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 9: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 10/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 10: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 11/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 11: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 12/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 12: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 13/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 13: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 14/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 14: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 15/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 15: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 16/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 16: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 17/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 17: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 18/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 18: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 19/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 19: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 20/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 20: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 21/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 21: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 22/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 22: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 23/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 23: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 24/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 24: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 25/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 25: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 26/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 26: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 27/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 27: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 28/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 28: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 29/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 29: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 30/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 30: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 31/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 31: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 32/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 32: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 33/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 33: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 34/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 34: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 35/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 35: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 36/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 36: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 37/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 37: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 38/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 38: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 39/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 39: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 40/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 40: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 41/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 41: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 42/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 42: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 43/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 43: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 44/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 44: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 45/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 45: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 46/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 46: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 47/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 47: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 48/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 48: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 49/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 49: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 50/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 50: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 51/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 51: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 52/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 52: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 53/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 53: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 54/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 54: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 55/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 55: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 56/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 56: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 57/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 57: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 58/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 58: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 59/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 59: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 60/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 60: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 61/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 61: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 62/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 62: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 63/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 63: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 64/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 64: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 65/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 65: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 66/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 66: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 67/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 67: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 68/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 68: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 69/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 69: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 70/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 70: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 71/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 71: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 72/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 72: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 73/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 73: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 74/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 74: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 75/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 75: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 76/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 76: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 77/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 77: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 78/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 78: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 79/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 79: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 80/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 80: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 81/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 81: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 82/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 82: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 83/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 83: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 84/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 84: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 85/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 85: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 86/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 86: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 87/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 87: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 88/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 88: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 89/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 89: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 90/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 90: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 91/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 91: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 92/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 92: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 93/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 93: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 94/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 94: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 95/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 95: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 96/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 96: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 97/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 97: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 98/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 98: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 99/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 99: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 100/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 100: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 101/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 101: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 102/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 102: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 103/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 103: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 104/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 104: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 105/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 105: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 106/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 106: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 107/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 107: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 108/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 108: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 109/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 109: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 110/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 110: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 111/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 111: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 112/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 112: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 113/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 113: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 114/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 114: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 115/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 115: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 116/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 116: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 117/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 117: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 118/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 118: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 119/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 119: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 120/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 120: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 121/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 121: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 122/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 122: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 123/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 123: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 124/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 124: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 125/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 125: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 126/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 126: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 127/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 127: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 128/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 128: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 129/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 129: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 130/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 130: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 131/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 131: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 132/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 132: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 133/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 133: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 134/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 134: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 135/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 135: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 136/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 136: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 137/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 137: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 138/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 138: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 139/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 139: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 140/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 140: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 141/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 141: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 142/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 142: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 143/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 143: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 144/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 144: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 145/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 145: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 146/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 146: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 147/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 147: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 148/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 148: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 149/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 149: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 150/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 150: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 151/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 151: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 152/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 152: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 153/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 153: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 154/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 154: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 155/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 155: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 156/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 156: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 157/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 157: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 158/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 158: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 159/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 159: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 160/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 160: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 161/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 161: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 162/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 162: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 163/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 163: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 164/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 164: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 165/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 165: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 166/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 166: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 167/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 167: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 168/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 168: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 169/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 169: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 170/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 170: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 171/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 171: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 172/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 172: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 173/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 173: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 174/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 174: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 175/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 175: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 176/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 176: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 177/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 177: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 178/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 178: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 179/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 179: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 180/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 180: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 181/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 181: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 182/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 182: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 183/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 183: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 184/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 184: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 185/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 185: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 186/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 186: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 187/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 187: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 188/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 188: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 189/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 189: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 190/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 190: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 191/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 191: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 192/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 192: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 193/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 193: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 194/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 194: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 195/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 195: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 196/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 196: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 197/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 197: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 198/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 198: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 199/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 199: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 200/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 200: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 201/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1194 - loss: nan\n",
      "Epoch 201: val_accuracy did not improve from 0.12500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.1194 - loss: nan - val_accuracy: 0.1250 - val_loss: nan\n",
      "Epoch 201: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(252, 252, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy',mode='max',verbose=1,patience=200)\n",
    "mc = ModelCheckpoint('best_model.h5.keras',monitor='val_accuracy',mode='max',verbose=1,save_best_only=True)\n",
    "\n",
    "# 　原epochs=300,batch_size=512\n",
    "hist = model.fit(X_train,y_train, validation_data=(X_val,y_val), epochs=300,batch_size=512,callbacks=[es,mc])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T12:02:04.736871Z",
     "iopub.status.busy": "2024-03-23T12:02:04.736586Z",
     "iopub.status.idle": "2024-03-23T12:02:05.280923Z",
     "shell.execute_reply": "2024-03-23T12:02:05.280034Z",
     "shell.execute_reply.started": "2024-03-23T12:02:04.736848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'],label='train')\n",
    "plt.plot(hist.history['val_accuracy'],label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T12:03:44.209672Z",
     "iopub.status.busy": "2024-03-23T12:03:44.209284Z",
     "iopub.status.idle": "2024-03-23T12:03:44.258392Z",
     "shell.execute_reply": "2024-03-23T12:03:44.257442Z",
     "shell.execute_reply.started": "2024-03-23T12:03:44.209640Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "model = tf.keras.models.Sequential([\n",
    "                                    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(252,252,1)),\n",
    "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                    tf.keras.layers.Conv2D(16,(3,3),activation='relu'),\n",
    "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                    tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(100,activation='relu'),\n",
    "                                    tf.keras.layers.Dropout(0.5),\n",
    "                                    tf.keras.layers.Dense(2,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T12:04:01.300404Z",
     "iopub.status.busy": "2024-03-23T12:04:01.299701Z",
     "iopub.status.idle": "2024-03-23T12:06:50.539049Z",
     "shell.execute_reply": "2024-03-23T12:06:50.538152Z",
     "shell.execute_reply.started": "2024-03-23T12:04:01.300368Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[AW0000 00:00:1711195459.686010      84 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n",
      "2024-03-23 12:04:20.451405: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 2.47294, expected 2.10939\n",
      "2024-03-23 12:04:20.451477: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 2.41328, expected 2.04973\n",
      "2024-03-23 12:04:20.451488: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 2.62018, expected 2.25663\n",
      "2024-03-23 12:04:20.451498: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 2.49895, expected 2.1354\n",
      "2024-03-23 12:04:20.451506: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 2.33992, expected 1.97637\n",
      "2024-03-23 12:04:20.451515: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 10: 2.44382, expected 2.08027\n",
      "2024-03-23 12:04:20.451524: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 11: 2.28007, expected 1.91652\n",
      "2024-03-23 12:04:20.451533: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12: 1.99643, expected 1.63288\n",
      "2024-03-23 12:04:20.451542: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 23: 2.51274, expected 2.14919\n",
      "2024-03-23 12:04:20.451550: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 24: 2.54021, expected 2.17666\n",
      "2024-03-23 12:04:20.467239: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f32[32,16,250,250]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,252,252]{3,2,1,0}, f32[16,1,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n",
      "2024-03-23 12:04:20.467285: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n",
      "2024-03-23 12:04:20.467300: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n",
      "2024-03-23 12:04:20.467309: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n",
      "2024-03-23 12:04:20.467317: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n",
      "2024-03-23 12:04:20.467333: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n",
      "2024-03-23 12:04:20.868858: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 2.47294, expected 2.10939\n",
      "2024-03-23 12:04:20.868932: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 2.41328, expected 2.04973\n",
      "2024-03-23 12:04:20.868943: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 2.62018, expected 2.25663\n",
      "2024-03-23 12:04:20.868953: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 2.49895, expected 2.1354\n",
      "2024-03-23 12:04:20.868962: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 2.33992, expected 1.97637\n",
      "2024-03-23 12:04:20.868982: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 10: 2.44382, expected 2.08027\n",
      "2024-03-23 12:04:20.868992: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 11: 2.28007, expected 1.91652\n",
      "2024-03-23 12:04:20.869001: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12: 1.99643, expected 1.63288\n",
      "2024-03-23 12:04:20.869010: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 23: 2.51274, expected 2.14919\n",
      "2024-03-23 12:04:20.869019: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 24: 2.54021, expected 2.17666\n",
      "2024-03-23 12:04:20.885681: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f32[32,16,250,250]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,252,252]{3,2,1,0}, f32[16,1,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n",
      "2024-03-23 12:04:20.885756: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n",
      "2024-03-23 12:04:20.885768: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n",
      "2024-03-23 12:04:20.885776: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n",
      "2024-03-23 12:04:20.885785: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n",
      "2024-03-23 12:04:20.885805: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n",
      "2024-03-23 12:04:21.809185: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 2.05542, expected 1.74892\n",
      "2024-03-23 12:04:21.809254: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 2.00415, expected 1.69766\n",
      "2024-03-23 12:04:21.809272: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 2.05993, expected 1.75343\n",
      "2024-03-23 12:04:21.809285: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 2.01756, expected 1.71106\n",
      "2024-03-23 12:04:21.809296: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 1.39198, expected 1.08548\n",
      "2024-03-23 12:04:21.809307: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 10: 1.49244, expected 1.18595\n",
      "2024-03-23 12:04:21.809318: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 11: 1.95622, expected 1.64972\n",
      "2024-03-23 12:04:21.809331: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12: 1.49457, expected 1.18807\n",
      "2024-03-23 12:04:21.809341: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 24: 1.86157, expected 1.55507\n",
      "2024-03-23 12:04:21.809358: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 25: 1.96419, expected 1.6577\n",
      "2024-03-23 12:04:21.813787: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f32[8,16,250,250]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,1,252,252]{3,2,1,0}, f32[16,1,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n",
      "2024-03-23 12:04:21.813832: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n",
      "2024-03-23 12:04:21.813847: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n",
      "2024-03-23 12:04:21.813862: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n",
      "2024-03-23 12:04:21.813875: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n",
      "2024-03-23 12:04:21.813897: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n",
      "2024-03-23 12:04:21.927446: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 2.05542, expected 1.74892\n",
      "2024-03-23 12:04:21.927505: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 2.00415, expected 1.69766\n",
      "2024-03-23 12:04:21.927519: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 2.05993, expected 1.75343\n",
      "2024-03-23 12:04:21.927532: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 2.01756, expected 1.71106\n",
      "2024-03-23 12:04:21.927543: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 1.39198, expected 1.08548\n",
      "2024-03-23 12:04:21.927553: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 10: 1.49244, expected 1.18595\n",
      "2024-03-23 12:04:21.927563: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 11: 1.95622, expected 1.64972\n",
      "2024-03-23 12:04:21.927574: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12: 1.49457, expected 1.18807\n",
      "2024-03-23 12:04:21.927584: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 24: 1.86157, expected 1.55507\n",
      "2024-03-23 12:04:21.927596: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 25: 1.96419, expected 1.6577\n",
      "2024-03-23 12:04:21.929199: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f32[8,16,250,250]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,1,252,252]{3,2,1,0}, f32[16,1,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n",
      "2024-03-23 12:04:21.929226: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n",
      "2024-03-23 12:04:21.929239: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n",
      "2024-03-23 12:04:21.929251: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n",
      "2024-03-23 12:04:21.929260: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n",
      "2024-03-23 12:04:21.929279: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n",
      "                                              \n",
      "Epochs:   0%|          | 0/10 [00:21<?, ?it/s]\n",
      "Batches:   0%|          | 0/1 [00:21<?, ?it/s]\u001b[A\n",
      "Epochs:  10%|█         | 1/10 [00:21<03:10, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - val_loss: nan - val_acc: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                      \n",
      "Epochs:  10%|█         | 1/10 [00:37<03:10, 21.19s/it]\n",
      "Batches:   0%|          | 0/1 [00:16<?, ?it/s]\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:16<00:00, 16.66s/it]\u001b[A\n",
      "Epochs:  20%|██        | 2/10 [00:37<02:28, 18.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - val_loss: nan - val_acc: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                      \n",
      "Epochs:  20%|██        | 2/10 [00:54<02:28, 18.53s/it]\n",
      "Batches:   0%|          | 0/1 [00:16<?, ?it/s]\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:16<00:00, 16.57s/it]\u001b[A\n",
      "Epochs:  30%|███       | 3/10 [00:54<02:03, 17.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - val_loss: nan - val_acc: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                      \n",
      "Epochs:  30%|███       | 3/10 [01:10<02:03, 17.64s/it]\n",
      "Batches:   0%|          | 0/1 [00:16<?, ?it/s]\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:16<00:00, 16.41s/it]\u001b[A\n",
      "Epochs:  40%|████      | 4/10 [01:10<01:42, 17.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - val_loss: nan - val_acc: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                      \n",
      "Epochs:  40%|████      | 4/10 [01:27<01:42, 17.16s/it]\n",
      "Batches:   0%|          | 0/1 [00:16<?, ?it/s]\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:16<00:00, 16.57s/it]\u001b[A\n",
      "Epochs:  50%|█████     | 5/10 [01:27<01:24, 16.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - val_loss: nan - val_acc: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                      \n",
      "Epochs:  50%|█████     | 5/10 [01:43<01:24, 16.95s/it]\n",
      "Batches:   0%|          | 0/1 [00:16<?, ?it/s]\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:16<00:00, 16.48s/it]\u001b[A\n",
      "Epochs:  60%|██████    | 6/10 [01:43<01:07, 16.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - val_loss: nan - val_acc: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                      \n",
      "Epochs:  60%|██████    | 6/10 [02:00<01:07, 16.79s/it]\n",
      "Batches:   0%|          | 0/1 [00:16<?, ?it/s]\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:16<00:00, 16.39s/it]\u001b[A\n",
      "Epochs:  70%|███████   | 7/10 [02:00<00:49, 16.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - val_loss: nan - val_acc: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                      \n",
      "Epochs:  70%|███████   | 7/10 [02:16<00:49, 16.66s/it]\n",
      "Batches:   0%|          | 0/1 [00:16<?, ?it/s]\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:16<00:00, 16.34s/it]\u001b[A\n",
      "Epochs:  80%|████████  | 8/10 [02:16<00:33, 16.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - val_loss: nan - val_acc: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                      \n",
      "Epochs:  80%|████████  | 8/10 [02:32<00:33, 16.56s/it]\n",
      "Batches:   0%|          | 0/1 [00:16<?, ?it/s]\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:16<00:00, 16.31s/it]\u001b[A\n",
      "Epochs:  90%|█████████ | 9/10 [02:32<00:16, 16.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - val_loss: nan - val_acc: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                      \n",
      "Epochs:  90%|█████████ | 9/10 [02:49<00:16, 16.49s/it]\n",
      "Batches:   0%|          | 0/1 [00:16<?, ?it/s]\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:16<00:00, 16.22s/it]\u001b[A\n",
      "Epochs: 100%|██████████| 10/10 [02:49<00:00, 16.92s/it][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - val_loss: nan - val_acc: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")  # 指定在第一个 GPU 上运行模型\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 360\n",
    "\n",
    "with strategy.scope():\n",
    "    model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=200)\n",
    "    mc = ModelCheckpoint('best_model.weights.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "        # 训练循环代码\n",
    "         for batch in tqdm(range(0, len(X_train), batch_size), desc=\"Batches\", leave=False):\n",
    "                \n",
    "                X_batch = X_train[batch:batch+batch_size].cpu().numpy()  # 将X_batch从CUDA设备复制到主机内存并转换为NumPy数组\n",
    "                y_batch = y_train[batch:batch+batch_size].cpu().numpy()  # 将y_batch从CUDA设备复制到主机内存并转换为NumPy数组\n",
    "                model.train_on_batch(X_batch, y_batch)\n",
    "\n",
    "                # Validation\n",
    "                val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "                tqdm.write(f\"Epoch {epoch+1}/{epochs} - val_loss: {val_loss:.4f} - val_acc: {val_acc:.4f}\")\n",
    "\n",
    "                # Early stopping\n",
    "                es.on_epoch_end(epoch, logs={\"val_accuracy\": val_acc})\n",
    "\n",
    "                # Model checkpoint\n",
    "                if es.stopped_epoch == epoch:\n",
    "                    model_to_save = tf.keras.models.Sequential([\n",
    "                        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(252, 252, 1)),\n",
    "                        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                        tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "                        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                        tf.keras.layers.Flatten(),\n",
    "                        tf.keras.layers.Dense(100, activation='relu'),\n",
    "                        tf.keras.layers.Dropout(0.5),\n",
    "                        tf.keras.layers.Dense(2, activation='softmax')\n",
    "                    ])\n",
    "\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4615308,
     "sourceId": 7866632,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
